{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Encryptor_Decrypter_Net1_V1_12x.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OZ7nAf50AkBu",
        "outputId": "a0eb69c6-b4a2-4ec4-cb86-6b006b361ee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "pip install tensorboardcolab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wo8FpE5nAl6_",
        "outputId": "f9bd4a40-7c7d-4674-99c2-ea77f70e1700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "tbc=TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://482d1da0.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hfntcH0W00ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "191765f3-e4bd-44b4-9e7c-d50326def39b"
      },
      "source": [
        "from keras import Sequential\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1jPmeBAc9dD-",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5DyLy5GF7lnD",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GrY57mTsbIaw",
        "colab": {}
      },
      "source": [
        "def create_labels(paragraph, hashmap):\n",
        "    # paragraph = paragraph.lower()\n",
        "    output = []\n",
        "    for i in paragraph:\n",
        "        output.append(list(map(int,str(hashmap[i]))))\n",
        "    \n",
        "    return np.array(output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq-taeGtXApQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# para = \" ab b a\"\n",
        "hashmap = {'x': 10001100, '^': 11010110, '@': 11100001, ')': 10100000, ' ': 10011000, '+': 10010100,\n",
        " '4': 10001011, 'M': 10100011,\n",
        "  '-': 10001010, 'd': 11001111, 'F': 10111000, '/': 10111110, 'C': 11101111, 'm': 10100111,\n",
        "   'S': 10111111, '=': 11101110, '<': 11010001, '`': 10110001, '%': 11001001, 'e': 10001110,\n",
        "           '\"': 11011010, '&': 10000111, 'p': 11000100, '>': 11000011, 'v': 10010000, 'q': 10010110, 'H': 10100100,\n",
        "           '$': 11100110, 'T': 10000110, ':': 10100001, 'B': 11100011, 'R': 10110011, '?': 11010000, '6': 11101101, 'V': 11110100, '2': 11001011, 't': 10010111, 'D': 10001000, 'W': 11101100, '3': 11101010, 'J': 11111111, 'g': 11111011, '.': 11011101, 'O': 10001101, '!': 11100101, 'L': 10010011,\n",
        "    ']': 11011011, 'I': 10111101, 'y': 11000001, 'X': 10000011, 'j': 10111010, 'Z': 10101101, ',': 11111101,\n",
        "           'h': 11011111, '_': 11010111, 'P': 11001110, '0': 11101011, 'k': 10111011, 'a': 10101001, 'r': 11110001, '\\\\': 11000000, 'Y': 10110000, 'l': 10110111, 'b': 11110000, 'z': 10101111, 's': 11001101, ';': 11110010, 'c': 11110111, 'U': 10000101, '[': 11001010, 'o': 11101001, 'N': 10100101, '1': 11001000, '7': 10011011, 'f': 10101100, 'G': 10111001, 'A': 10111100, 'n': 10000100, '5': 11000111, 'E': 10100010, '9': 11100010, 'Q': 11110011,\n",
        "     \"'\": 10011100, 'w': 11111110, 'i': 11001100, '8': 11100111, '#': 11011000, 'K': 10011101, '(': 10011111, 'u': 10011001, '*': 11100100}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtWygSd5XApS",
        "colab_type": "code",
        "outputId": "40b0cf77-cc38-45db-f46d-685c353d6200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(len(hashmap))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qKNaI7jVaDnP",
        "colab": {}
      },
      "source": [
        "# Y_train = create_labels(para, hashmap)\n",
        "# print(Y_train.shape)\n",
        "# print(Y_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bB6b260kLbtK",
        "colab": {}
      },
      "source": [
        "# def create_input_array(word):\n",
        "#     arrmain = []\n",
        "#     for letter in word:\n",
        "#         if(letter != ' '):\n",
        "#             arr = np.zeros(27)\n",
        "#             index = ord(letter) - 97\n",
        "#             arr[index] += 1\n",
        "#             arrmain.append(arr)\n",
        "#         else:\n",
        "#             arr = np.zeros(27)\n",
        "#             index2 = ord(' ') - 6\n",
        "#             arr[index2] += 1\n",
        "#             arrmain.append(arr)\n",
        "#     return(np.array(arrmain))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-dzP-JDXApa",
        "colab_type": "code",
        "outputId": "9a525d16-bfac-4cde-af9e-0c493836f1d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "characters = [chr(i) for i in range(32, 123)]\n",
        "# print(sorted(characters))\n",
        "# print(ord(' '))\n",
        "# print(ord('z'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "32\n",
            "122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fSezlSDXApd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_input_array(word):\n",
        "    enc_l = []\n",
        "    for i in word:\n",
        "        arr = np.zeros(91)\n",
        "        enc = ord(i) - 32\n",
        "#         print(enc)\n",
        "        arr[enc] += 1\n",
        "        enc_l.append(arr)\n",
        "    return(np.array(enc_l))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p87WM00gMuGM",
        "colab": {}
      },
      "source": [
        "# w = 'ab c'\n",
        "# inp_arr = create_input_array(w)\n",
        "# print(inp_arr)\n",
        "# print(inp_arr.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LIzJTfqpaize",
        "colab": {}
      },
      "source": [
        "X_train_string = '''b'Kp]I! S t\"ayQ<w )8tfwP 178 ]R?Dop gBv )1 mJE#@N79-= f+ b*=z @<z`-e>mg$ `5Uv8)j*= fyVUjtBI1^ /+ktvxSF[ 6n*VJj9Pu 5[3>0 L9# *6;X k/y[ \\'OSQ2,RCF 5.razd4T `HW;#=84rs _ fX[;+ z?!m0V P1inV7C.kF \\'k5,bO ziyek H3.TAG\\\\1 w?cf652J PYg-x1 .oqv bm ] $VCIi^Hnu WDHb az6d<Q7L% vi)6]J8 7X Leb 2N4 3EUe: wUsr $;v #gp i1 Sd b7e@C:.I^< 64t$UdmiC b1 y3u=2*$h 6K3ex\" 2y%?c z *(SK[C -96\\\\ Vx%zq2 Z N!;BKSh ]d[t;4< u/aF7;R* B6@iq\\'d& PT \\' eJw6vz@4g/ NH@) 9L6o%b_v#! 4w6.f f]rp%2\"b\\'q 1 IAB[Z\\\\vl=0 VA v*^L<f r=vm\"gS9 JXj.W$ B<bw5L7zk a`*9;s[# /v-+\"Q n.GPh ,KmgE;Mfk& bV9?Zo XArG_  Go*nD,U .@\"!2xhaz` Eyx 4W;r>N17\"l .!m/YDU9 @x>\\\\th8   r 49 ]cN_`gWM .^+lDGc Xu^-+ Py8?J:xv\" (2/ aX!t<>  $aR we3)bHT u2#>B@o)d SsAbV bOL?] b1G%;+L4C2 kY(*zJ TPzfk 8[Imd` CK [`a;vtK 1.X=!4<ut ` Ym%xF-J ,Z5zEa\\\\uj Swn= W=8J.aSys  6# w.\"o/x2tM y8 )Y-$ r.V$gTh1= Tu @T LPX . Bl2UQM5 rFyk\"_Lv o0MV ,I.m\\\\)?n 1o4s2pqQ<n mU5iB`FG +$x6LyIo0  hEWB] V$F8+iR q:Nz LA\"sm pmvA y)be>=8/q \" \"e,RiT!a `*:GiUu,a vwd$\\\\J &8\\\\ ad -Ll%)0U  zSWQ?s [-D a.o( D`/LVy ,Nc\\\\R_hXU Ap)_5Nur HF5?TqK ,t8? QD [v&0/g] c2xW;3# Y O^/9#xupg Y <ndO m G)Y`W=H\\' ]@w T3=l28\\'K< qr+ mt/Pw5nE; ]P3I5+Q*. 4 r$R\\\\8 Gh -W>V$Q^ #94gwd c-C\\'T4D]i^ $!# +M=L\\'< J8]2 kCQZid&<: q#1d.L4/ B[A qKNuS<Fo 7 &a$ rxL.6 ^>m\\\\icO ljuZ?63r4H e=JREx+ R*#WgF2KBu , DQESp \"Lu ^buw $V>P7 +9=8S 3?I,jw U- E>[$ uUQcG 0d ;]SC eb*_\"+ jM\\'VYFk &T ulRH,ti D@Z<H 6:m;z hBc_gk q <0*W47\\\\v os Mq2\\'ixuj QX;u#R/ j I4\"D 4Yb N- *X.! X&J?B\"O S0_Yxi1bB uL9x7q @ 0K^N d,U;vRm @\\' GXRq=\\\\]x9 nA&JkvH( Rw, `\":3 sg pD,Mb # i?r=:% N$\"e XVKUs  8mXW)+1x =?>.B0 #!rW(y@c/ )1IX,\\' HLhn82 $Q i,$Ld. \\'Dj3 za If&@g+MS_e pM\\'C; -2w#e6n0!I Yu@<M n,U-KybB TmQW 206N]t &H>*/TCiy 6z`20 PA?9  [Ge)2 !CM_e :KPlH5e\\' .]F=z ZC (dVD#6e pw?a=:P EydjZYGRpV nz_Rs !hN.9C\"x JbRm $6<I n^N/u\\\\,[-x %+ > /Pc\\'6 t \\\\#:7jkfh 1=^b:`\" a; q ?= MI_oY[7xf Lf<qUC6pb? >/U\\\\VbE87 #> \\\\)Co xmGB3zP4Fj \" _w-*jc`K `_5wDMP^! /ZN0 #1* ,HX y*Y&R\" dPfyk\\\\`JmE < D9cC=L7;([ tlsiuK /1 Yb7g2dHx3  4*Th26%rA Xl+vqKhw zF-<Km(B :z(%gfoqt mN\"^I08Qo > w.o] N a EyC T6<O= %< v&k_ h_C,7o AKV,C8]JBr OB&S iSc\\' 5&J>CX #f `3#mv\\\\ ZfMNxO V[G&\\' g4lU9$ W? i>R efZ\\\\I ?  &fW-253Kp i t3.,YE EV8# T_l QfA , XBlCu 5,\":A[O7Y Z]a,.Do &q,cn-C> WQb<\\\\` >pR6<5XWvb >o2d[3Fs W`\" ;T\\'Bz\",jE S ^t, (6Iy2)nZ j;LKY^S PLXNC =QUWq 8-Ze^l y\\\\cYS^%<n 1:qHwyjE r*V/1 MSjN AhuQN2\"Z_w U zvGf64h<yd nis1o7NaV T]C(Aqm? JSyT+xznO  NP]^#2qIiU iU^h*L PBWvyue1^ Yz2 `2^ 7\\'xn> ?Wv[rH,Fa H.d:-G ([ JxmjAwe.Q ]8Nx0ZM3@< xvP5eou xhIM cqp/(C\\'Jw) \\'H= oAPm:\"v@ $!Gx=-\\\\P aKWo .f4Wpw\\\\)Tx kv> wWt Xnq;!^0 N . FCK h5c3s=EITX ?v o1 Z9Ev[8=yI CHAMQdSjh WiX9q] m&L<s ku]5c<&, qhSI7M?*u PdSAesLM6 .u1J\\\\iA! 1 Z5M:fp %[9GH:RC RuxY `G=:,7> [;2NB c`/Ud9E - W:_ i#]VR2: 6: jo!* EMt w o% S^n6CY7 mJ p-A,r/gK SH7w842 =DU&eMtw %9$an ?\\'xf9 zaGr5-vu! FQCG^H=Pp 6hTz_L,[ fV %^J hE/i%b ;b5<y:r!VY %Zp@ ) qnMHc /7vS : O>s1yWbNPS \\\\kCnXL ]z`\\'nX+ _-YM2A 7^5: ]wOm CIU%FQ?1 ( ] O\" 2uFva0LZ# YTpafE(*19 w = l<O#8jm p4  /p) %Fn<- 0 \\',fH OdU(sZ 9 bS.v q6F!\\\\y !F2[O 2\\'],` ceZRX\\'UNa asK?-\"S CJqD td +>v#0_f\\\\F u(o2qk=jx\" \"4t yG= OF&Qd8 &G K Zo>zjFp\"h] G<= vFomWTq0Y% :!3 U S`Qc ]YE.C\\'r( [.v\\\\ EhWRH /nE<3`Q  c ;1X,)8aem Ks(nSWU 7? vHPKL6Ex c . _*(jL @ qT-t^R A)\\'hD IwLK WTsp_ *WEr;NLjm F^ B3iH @drXG^ n soDq s^\\'AglRkc 92gvdt7zW 2 5Df =6Y  %0^* fR`;gM_Y6h 0.8FUE;t lZx R\"D1Y]dX V8eRtG(Kb, f9 Vdiy>SL/O2 .W 73Z*$`6^ B$xO iC,:a0fq;2 + 6vui : [\\'MUj tcp#rB\\'A Y#q )yno l?/bz]N& V7MN$Pthm N o>8Z+i?; @\"Y> J7] i= cFv RevgrJD d0@W5  931&ym : @Qm5sI+L^ HRw i]RoA2#y) 8FuEP= t>oK \\\\ ]>zrR# q0\\\\*^ jma ;e.ux _ Y7+w0 C[RBU -D la3 CP^ 1`XDw:9t 9yhT N\"=!69R&d* > Rjh2Ss,: 6F5@\"b q)iZze`bM &6R\\'1 BMA_ *Md` N0kez:., meo&Y; \\'L6 Ca p 0mb.`:s& [ W@xj.T= 8k!_R , ^F G= wZif OHF8lEwd27 6 O ; #L\\\\,Q(+>7 &f1dQ8!O N -k@ FZ\\'LUYiwf & sB57@yQ- 5cjWrt%ai< tHsjL! oMv Rgn >s 5i2\\\\ \"6W\\\\Ik kW GIR9?N&qK gY! H=! N.jgoh+ QS mYxba n2cB=6, C)4 =@!qB 9;d E^M1BywqJ` )yFsQ 4_*ts 2G+L \\\\2m x aRk7U Ghp*ADqo l i 0]A`at x \\\\D12- LS \"q@Dyrn .dqgOi]W o\\\\<v.KOxA umYJP? he\\\\Ci^z sW VU4v `. cYA2  S EzU %4 uC\\\\m4 PK38rB , mj\\'_+kUz T93! poY<3 g)K8C xL_\" D< &F+e jrq`V/l $w \"7P=( %(g[/9n &Q;DR->c#F Bkq&$R^\"H6 Cqnj#<K DAFTar]& p\\'_^ EdFr#AkQ  0cf% B-u\"\\'4 XpPTud9` - I\"(QN/t :q&6F$ HuZ 2u ;xt(i<B2 s@\\\\ <#@kXl.V` >3J5d d *yD-k9\\\\ i4CfES-j 4\\',EX.Bjby M2G.I:bliu /2.7mPjAJ\\\\ ]8)Z1 )-wgsfI[a/  Mo=H8z\" qA\\\\ ?eD8zHx;p \".1=WN c:8q  A8a$\"jb g a)\\'s ^`D q\"vRC2 Bc b;T dXz&fJt! ^2 \\\\C1 - []B*w6rHkU TvU0 es-g/uM IqVp$)6Mv =#\"S: x0Ya,j4T 8I(H KD$,   O+\\'F y : #cbG tI1As V]M6=e )N3 *Mi;&!Oc) 1MQ 7Ke3 oR`k-z !3=S Xoa <9?1n0:^`* o>\"Qz pDM]R0 ]-/`8aoU=* bWR jcDtrq 9 zUEZX!t t.g\\'a X(2!70z+k [nbo [zRHlJp\"+ rZE5.T_l EIn^(z; Ee.giY8rA, CFxq6v(V B$an1])5 \" Xx\\\\1vr+EGk TZN7g 93*wj! <%96 x^h#fI$ .oN0xOn=5: 5V?L)F!M qw?Lf zfF URVE=$5d  =An0?`wo E$`K8n 8=`3Qa1 iG1r GZygw. JX@DKx7 %!+ x*\"8m _] QvN\\\\ qM (R.A2 j\\\\Ty[m9 861^\"i@yfS HK Gf =dW etcJ\\'w0 aD@S t pF! 7-g(6)/ i] #j 5n;uY1rg Ug7Kn9oVA !\"#  Elno9 wKBvukR V*=@1O \\'\\\\@<R qun $wuQ[O jsyR\"8eUC6 \\'*s Q e12,Sv)>&` *24r/!<co\" W3 WE,F2] rb 1/_H9O \\\\Zv EH=Vc2 %\\'X?k GR F.Z m ,P0\" \\\\ jM;NA<v> 1iE3h;Gr) j *UF3zZg2r_ F[h;Hk3 @H)Cni, u:< gB(c2 z @F5T*$iv ]Ao \\'@j1_?\\\\d#v .L \\\\9/\\'8 GDJF9KqeM s9r\\\\Aa _$(J`Qt #jK $p? y=G BamA&8cK?g kqVMpdem), 0yIx;` Fh g=ZlVemp9T Sb v;*L-m9Eo !;O #ny6oY\" _=K 4h>n /z!f ^FG7 #m/L!\\\\ %mt3+ noSIt1`h OG i +[9d &0y.)]8 )w.*,6 ps Z+Q=[ XZgCT#mPfB  >&w wm[MStu iy/H0Tl^C M u\"Ea9>L?F N!QL cC\"ya2+7 l:n W=3.V9aT\\\\ [35V   8[K#ejb PTZz+W \\']3dCv lW1(H2&$q WaRI3C :T6-(`<Bo W(o58 v /> NeR8 twzd!O#+ ;-?>l 4Lp:>TfQ/h KI1-R&3W8_ xOSA`XY(? Y_ k]9@-^ .;(>/ T0y R &-Zxn R^ /$tIw7\\'Bd i`F3Jy#9T0 z)MWjy ]yu TGF4v\\\\ .LQ 685E v yM =zSt\\'(+ jA( I Bo(=vM!f\\\\C `3#DZ0]b K# @2 P l E4 cG1>#Td  _s534WY2 A^ =6ieA1Q bm5cwn gq+es@f ;5Fb= $7 0s+ #m+0 $YsLj@w6 ! qEG Wgq;` 6K\\\\4a(\\'- -6$f=&qVP\" K$x)g\\'6L7q >! ; zZSOLwG T-bcM&is (u*7H0:M tI>+OP6 ZuA8g C_h8 =MX(Z\\\\q $o y7/ q!y4=) nQj*+P^JMd 8L!i_ 3 b@_L]q. # Q(4S _X9!v v #xy_ &- TOjF! I4[ineR]Jq Fcd@7s[D4 X&8qD@gJS wVWx .ozjqJM PYfs?g \\'4LW; O&cJz,9*6 0qn.<- c &w 1UKw)uH Rz_iqx]Uvt ieu.2 J 9-`521 8,D 7\\\\%BFz#s/ 2B z5ZQI 94 aI# >(Ny0ef$ : Lc zwA\" *=.Y6HBI8 ZW0?\\'\"> l\\'_h l fG@7!e wVJ#H4D yrR\"vs k sM[G G+9>b`LBR E UvHxj 8$2+- Cus-!AjNG< gytl) ltMK@Zj vzA[73W8 m`c K6m\"/f\\\\ O ^w m C6bm 0 <_=)Q fE[C gy m : /u D `0+ NX cnitB>=I?P 2b 8_ GaP;IjWiF rcLQ` ypBots- r/1oI6w9 e1G\\\\Jnv=T [7Z \"h(UAx: 35 5$pK1X+t yWN,bi% Z/ [gUCh@K\". O ,yxM7EzA(p & n(!w NyO -HKT =2&K pM 7Q1vn K V14vSkHWab :d3XlJz#mr L&_=c /9#^ q8,N!Ed/w mET;pM\"Fu L W L6 wD jTE&i )Uq!ZF LUG4dP. [C,S ] Y0 !y Hwb/ 3uk1 Sgxcp;OA U F!9 ;Fb\\'vh]C$G MecnUA   _*Sl b]5>k0  $bl`wI_t hz0U 7*yB=hx +/]-!_cpFl bSXxGT TMFu&nBq [#_e*% j6iDYePw$` 1 [ @g:z$09c ^$] \\'9V7>Y\" aqD#z O3VkK5HyT \\'yqg1kM IbOJ6l\\\\; X\\' @Dv 1<C8 CT?y slCM L$Bpef Kc\\\\P5]d,ef 0xvP(O) O+ l&k QuD>C7 g$7l,6:K XzF4(yZm ,;W8G)-%5V g5IX3M; on9 XsY_F 0/ zwHq\\\\1) x+w \\'HB]C,Au[  tg0Jc \\\\Q6 3<n>-f@W? 6FYP7>S!= /BRbOf<Ms@  y?-=N/0]4 Wna0STv*\\' nJqH0%Y1D sZ)yu %=)cA *W\" 3fdELH<J p GHTvfhN/e +v \\'][J h %.C6sjUo I@EU f9[> 8$ sr+1BG`- S\\\\3.9 `@ f1H>\"v \\'So R Yg+b[x\"@#? x H /If 2.c@xzm Tyo*L VTfr8P1B )hJS 3l<$. S\"!F(& se\"(^XKR Fzt4 tN0.\\'oG1[ &0K7Tq  vSdw\"B@[` \"[6Uy.Iz]` J $!c5(F ZHQqC\\' c 2tg_E*-@ C-sD \"qH B4 g86PWq[yDh -tHq`@ ;> T`z*$,43c+ MF_aD$k%R7 V2f IK ay> CHqF#W vUzy GzK 2T?\"knx>% ?H`;vq -m[=H(\\\\Yy` L \\'zA#[:.  ^D<@-K\\\\M9 .\\\\,mfR1y2k :v@ 5T_[ON moW eS`CH6_ %;(c :bAq$? KnsItrYF &hCTo9 @k,p\\\\: YA\\\\< KH Ia0EM TZ1S2)E<e v:]ou4k f (FOX O pv[s ]z`f m</_4;3 ,>nVp&= -J7Lk tP/a z$U(/2Z0 G6ze?a$BL zl7\"-/BM t7Qm:N !=k4uiD %A$8[t %V#qa>$,kY nk/GJ ac.kBJ 4_Ke Ii nJS.q(^#e) Fx3b uU6: $pIFR(L\" Xs/2S r&bZCOR 9hb sgRwV /Put l\"\\\\PQq9T`@ i HN W vFj?E fP9RJn .6 2t! 8 Fp=]BG !@I F)_C dO$7Q#N4B5 kA M z-3N1>T Pl<% /AY-qW&v z>Km iO0#\\' rAVYKP9 ()Yl *Ug p 0o1 niAUZRm n9a(s@L! afze(@q 3kAi> RgB ;j%Hc F1o*gA S,*8 ktPUDL46b j1 P-i$aZ`8p[ DC(@s.M 1whM dT!.1,^jV? G!YPbx:j6 v i6 i7sx`_(ge = T`>3fJ9d C=w FPYC\\\\rbBx &%MQ Rj`;L *6+X`Kk Q[R \\'osg_8<4 SCg+$5X9 *i)w!b]` n <#[bi +c ?w9=^R 306*]9!U dZ-\\'5)\"Yu Bx:\\\\Jt \"S R Fy*YH9 daln7hr F/m6=P v B.#hoiz mw2+X0  @y!YJ O@ 8K !V+7N>cv  7?biOKSv *#z`I E -zTs\\\\8B N uH !1Jv u/x7]hz$ ;]\\'ojb_ i p*_ ?#<A&T`VRz -t0cf$8 b GF2>Xp]6J8 hRNv3 #f0m@[ w!F<D8H%1 y05Rw 2P1 >IvK Mnu`Br3\" )97+s#!F6` 2vNtEoU98 Z 7)ja 9\\\\i<* :hxE>#wW bYp15 Eq F$\\\\](&LaK[ REfS( p,wBosr pU bp)w?=x]t( JE Io u(7@G4bns deR6\\\\j_ jWc)t,v3 ^ hl[x A >f6*:(3r?e u h/;xnPc3 e%,&  rq?vhyTg '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwfSAJNQnB3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Alice = ''' abcdefghigjklmnopqrstuvx ysx d go abcdef hidsog '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E31b6IKkDLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in X_train_string:\n",
        "    if(ord(i)<32 or ord(i) > 122):\n",
        "        print(i, ord(i), chr(ord(i)), X_train_string.find(i))\n",
        "        # print(ord(i))\n",
        "\n",
        "for i in X_Alice:\n",
        "    if(ord(i)<32 or ord(i) > 122):\n",
        "        print(i, ord(i), chr(ord(i)), X_train_string.find(i))\n",
        "        # print(ord(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8h1d79VmO1K",
        "colab_type": "code",
        "outputId": "c8d5bc8f-9b18-4fda-d4a3-d0b496a84d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "X_train = create_input_array(X_train_string)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8076, 91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKKHsbbsnNgd",
        "colab_type": "code",
        "outputId": "05055fdc-50a8-4d46-97d1-a6407a66b77d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "X_test = create_input_array(X_Alice)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49, 91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k5OYt_3K4WTr",
        "outputId": "a1ee0c7a-9fb0-40db-dcb9-40ead078ca29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-ZZ0DyyIayLU",
        "outputId": "de63a7f6-0d7f-43fc-d65c-d71660a9d9db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "Y_train = create_labels(X_train_string, hashmap)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8076, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWmmrprqnWHW",
        "colab_type": "code",
        "outputId": "06a655e3-574d-43c1-db26-c7108fabf557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "Y_test = create_labels(X_Alice, hashmap)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5U9bNfTN4Yqy",
        "outputId": "87e04981-b526-4e46-9d3c-bf054877ef50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# print(Y_train)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8076, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agtO0Q-RnriE",
        "colab_type": "code",
        "outputId": "9f9e4166-164f-4cbd-c8ab-750efda1260e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# print(Y_test)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u-dwRyza2IQJ",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Dense(91, input_shape = (91,)))\n",
        "model.add(layers.LeakyReLU())\n",
        "\n",
        "\n",
        "model.add(layers.Dense(64))\n",
        "model.add(layers.LeakyReLU())\n",
        "\n",
        "model.add(layers.Dense(32))\n",
        "model.add(layers.LeakyReLU())\n",
        "\n",
        "model.add(layers.Dense(32))\n",
        "model.add(layers.LeakyReLU())\n",
        "\n",
        "model.add(layers.Dense(32))\n",
        "model.add(layers.LeakyReLU())\n",
        "\n",
        "model.add(layers.Dense(16))\n",
        "model.add(layers.LeakyReLU())\n",
        "\n",
        "model.add(layers.Dense(8))\n",
        "model.add(layers.LeakyReLU())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dPG761brDYw_",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.045\n",
        "epochs = 100\n",
        "batch_size = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I_KR8dgN9YCT",
        "colab": {}
      },
      "source": [
        "optim = optimizers.Adam(lr = learning_rate) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VEN17qsk-VG5",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint('/content/encrypt_1.h5', monitor = 'val_loss', verbose = 1, save_best_only = True, save_weights_only = True)\n",
        "reducelr = ReduceLROnPlateau(monitor = 'val_loss', verbose = 1, patience = 5,factor = 0.05, min_lr = 0.003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wd49fo9K-_pZ",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = optim, loss = 'mean_squared_error', metrics = ['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7YrLUGHzraBA",
        "outputId": "f70b770a-70aa-4ad2-f701-802c1fff8d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_100 (Dense)            (None, 91)                8372      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_100 (LeakyReLU)  (None, 91)                0         \n",
            "_________________________________________________________________\n",
            "dense_101 (Dense)            (None, 64)                5888      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_101 (LeakyReLU)  (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_102 (LeakyReLU)  (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_103 (LeakyReLU)  (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_104 (Dense)            (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_104 (LeakyReLU)  (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_105 (Dense)            (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_105 (LeakyReLU)  (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_106 (Dense)            (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_106 (LeakyReLU)  (None, 8)                 0         \n",
            "=================================================================\n",
            "Total params: 19,116\n",
            "Trainable params: 19,116\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KDuzHnbE_ryn",
        "outputId": "db8b77aa-e91b-49d3-a1cd-8e720767419e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train, Y_train, batch_size = None, epochs = epochs, verbose = 1, callbacks = [checkpoint, reducelr], validation_split = 0.1)"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7268 samples, validate on 808 samples\n",
            "Epoch 1/100\n",
            "7268/7268 [==============================] - 3s 395us/step - loss: 0.1191 - acc: 0.4496 - val_loss: 0.0116 - val_acc: 0.1238\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01163, saving model to /content/encrypt_1.h5\n",
            "Epoch 2/100\n",
            "7268/7268 [==============================] - 1s 203us/step - loss: 0.0032 - acc: 0.2170 - val_loss: 9.5386e-04 - val_acc: 0.1225\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01163 to 0.00095, saving model to /content/encrypt_1.h5\n",
            "Epoch 3/100\n",
            "7268/7268 [==============================] - 1s 204us/step - loss: 8.9585e-04 - acc: 0.1906 - val_loss: 7.7176e-04 - val_acc: 0.1757\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00095 to 0.00077, saving model to /content/encrypt_1.h5\n",
            "Epoch 4/100\n",
            "7268/7268 [==============================] - 1s 203us/step - loss: 0.0040 - acc: 0.1965 - val_loss: 0.0180 - val_acc: 0.2228\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.00077\n",
            "Epoch 5/100\n",
            "7268/7268 [==============================] - 1s 201us/step - loss: 0.0609 - acc: 0.3374 - val_loss: 0.0223 - val_acc: 0.4480\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.00077\n",
            "Epoch 6/100\n",
            "7268/7268 [==============================] - 1s 201us/step - loss: 0.0039 - acc: 0.1979 - val_loss: 6.7837e-05 - val_acc: 0.3144\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00077 to 0.00007, saving model to /content/encrypt_1.h5\n",
            "Epoch 7/100\n",
            "7268/7268 [==============================] - 1s 203us/step - loss: 1.9543e-05 - acc: 0.2195 - val_loss: 7.7434e-06 - val_acc: 0.1572\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00007 to 0.00001, saving model to /content/encrypt_1.h5\n",
            "Epoch 8/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 3.7223e-06 - acc: 0.2023 - val_loss: 2.4877e-06 - val_acc: 0.1101\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00001 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "Epoch 9/100\n",
            "7268/7268 [==============================] - 1s 198us/step - loss: 2.4319e-06 - acc: 0.1768 - val_loss: 3.2159e-06 - val_acc: 0.1547\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.00000\n",
            "Epoch 10/100\n",
            "7268/7268 [==============================] - 1s 203us/step - loss: 1.3842e-05 - acc: 0.1714 - val_loss: 1.0941e-04 - val_acc: 0.1869\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00000\n",
            "Epoch 11/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 0.0021 - acc: 0.2025 - val_loss: 0.0125 - val_acc: 0.1522\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 12/100\n",
            "7268/7268 [==============================] - 1s 205us/step - loss: 0.0010 - acc: 0.1490 - val_loss: 1.5932e-04 - val_acc: 0.0978\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00000\n",
            "Epoch 13/100\n",
            "7268/7268 [==============================] - 1s 198us/step - loss: 9.4990e-05 - acc: 0.1069 - val_loss: 5.6107e-05 - val_acc: 0.0495\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00000\n",
            "Epoch 14/100\n",
            "7268/7268 [==============================] - 1s 201us/step - loss: 3.6205e-05 - acc: 0.0977 - val_loss: 2.3185e-05 - val_acc: 0.0557\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00000\n",
            "Epoch 15/100\n",
            "7268/7268 [==============================] - 1s 202us/step - loss: 1.6065e-05 - acc: 0.0965 - val_loss: 1.0616e-05 - val_acc: 0.0334\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00000\n",
            "Epoch 16/100\n",
            "7268/7268 [==============================] - 2s 207us/step - loss: 7.5405e-06 - acc: 0.0875 - val_loss: 5.0857e-06 - val_acc: 0.0532\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 17/100\n",
            "7268/7268 [==============================] - 1s 195us/step - loss: 3.6225e-06 - acc: 0.1000 - val_loss: 2.4729e-06 - val_acc: 0.0866\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "Epoch 18/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 1.7914e-06 - acc: 0.0955 - val_loss: 1.2180e-06 - val_acc: 0.0755\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "Epoch 19/100\n",
            "7268/7268 [==============================] - 1s 197us/step - loss: 9.0786e-07 - acc: 0.0951 - val_loss: 6.4866e-07 - val_acc: 0.0569\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "Epoch 20/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 4.7308e-07 - acc: 0.0978 - val_loss: 3.4044e-07 - val_acc: 0.1374\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "Epoch 21/100\n",
            "7268/7268 [==============================] - 1s 196us/step - loss: 2.4831e-07 - acc: 0.1031 - val_loss: 1.8910e-07 - val_acc: 0.1473\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 22/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 1.3337e-07 - acc: 0.1146 - val_loss: 9.6393e-08 - val_acc: 0.2475\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "Epoch 23/100\n",
            "7268/7268 [==============================] - 1s 197us/step - loss: 6.9130e-08 - acc: 0.1344 - val_loss: 5.1136e-08 - val_acc: 0.0421\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "Epoch 24/100\n",
            "7268/7268 [==============================] - 1s 193us/step - loss: 3.5120e-08 - acc: 0.1357 - val_loss: 2.5581e-08 - val_acc: 0.1151\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "Epoch 25/100\n",
            "7268/7268 [==============================] - 1s 198us/step - loss: 1.6820e-08 - acc: 0.1350 - val_loss: 1.1010e-08 - val_acc: 0.0569\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "Epoch 26/100\n",
            "7268/7268 [==============================] - 1s 201us/step - loss: 7.6217e-09 - acc: 0.1552 - val_loss: 4.6757e-09 - val_acc: 0.1139\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 27/100\n",
            "7268/7268 [==============================] - 1s 198us/step - loss: 3.2192e-09 - acc: 0.1593 - val_loss: 1.9765e-09 - val_acc: 0.0743\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "Epoch 28/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 1.2964e-09 - acc: 0.1718 - val_loss: 7.4325e-10 - val_acc: 0.2153\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "Epoch 29/100\n",
            "7268/7268 [==============================] - 1s 198us/step - loss: 4.8347e-10 - acc: 0.1779 - val_loss: 2.3791e-10 - val_acc: 0.1052\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "Epoch 30/100\n",
            "7268/7268 [==============================] - 1s 201us/step - loss: 1.6134e-10 - acc: 0.1820 - val_loss: 8.9735e-11 - val_acc: 0.1498\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "Epoch 31/100\n",
            "7268/7268 [==============================] - 1s 200us/step - loss: 5.5444e-11 - acc: 0.1924 - val_loss: 2.4656e-11 - val_acc: 0.0755\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 32/100\n",
            "7268/7268 [==============================] - 1s 198us/step - loss: 1.9668e-11 - acc: 0.1901 - val_loss: 1.6810e-11 - val_acc: 0.1720\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.00000 to 0.00000, saving model to /content/encrypt_1.h5\n",
            "Epoch 33/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 2.1746e-10 - acc: 0.1677 - val_loss: 1.0606e-08 - val_acc: 0.2822\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00000\n",
            "Epoch 34/100\n",
            "7268/7268 [==============================] - 1s 198us/step - loss: 4.3341e-06 - acc: 0.1705 - val_loss: 4.2833e-05 - val_acc: 0.0210\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00000\n",
            "Epoch 35/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 7.3415e-05 - acc: 0.1670 - val_loss: 4.0138e-05 - val_acc: 0.0903\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00000\n",
            "Epoch 36/100\n",
            "7268/7268 [==============================] - 1s 202us/step - loss: 3.4082e-05 - acc: 0.1718 - val_loss: 1.2651e-05 - val_acc: 0.3045\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 37/100\n",
            "7268/7268 [==============================] - 1s 195us/step - loss: 1.6854e-05 - acc: 0.1763 - val_loss: 1.2096e-05 - val_acc: 0.2178\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00000\n",
            "Epoch 38/100\n",
            "7268/7268 [==============================] - 1s 194us/step - loss: 2.1551e-05 - acc: 0.1677 - val_loss: 7.7310e-05 - val_acc: 0.0569\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00000\n",
            "Epoch 39/100\n",
            "7268/7268 [==============================] - 1s 197us/step - loss: 2.4162e-04 - acc: 0.1801 - val_loss: 9.3900e-05 - val_acc: 0.0891\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00000\n",
            "Epoch 40/100\n",
            "7268/7268 [==============================] - 1s 196us/step - loss: 8.7056e-05 - acc: 0.1677 - val_loss: 8.6339e-06 - val_acc: 0.3193\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00000\n",
            "Epoch 41/100\n",
            "7268/7268 [==============================] - 1s 198us/step - loss: 1.5968e-06 - acc: 0.1677 - val_loss: 2.2295e-07 - val_acc: 0.0532\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 42/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 3.7836e-07 - acc: 0.1742 - val_loss: 3.0465e-07 - val_acc: 0.4344\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00000\n",
            "Epoch 43/100\n",
            "7268/7268 [==============================] - 1s 198us/step - loss: 1.3126e-06 - acc: 0.1813 - val_loss: 1.2079e-05 - val_acc: 0.0037\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00000\n",
            "Epoch 44/100\n",
            "7268/7268 [==============================] - 1s 201us/step - loss: 3.3817e-04 - acc: 0.1813 - val_loss: 5.4837e-04 - val_acc: 0.0916\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00000\n",
            "Epoch 45/100\n",
            "7268/7268 [==============================] - 1s 195us/step - loss: 9.6738e-05 - acc: 0.1676 - val_loss: 3.8099e-06 - val_acc: 0.1485\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00000\n",
            "Epoch 46/100\n",
            "7268/7268 [==============================] - 1s 197us/step - loss: 9.0504e-07 - acc: 0.1668 - val_loss: 1.4632e-07 - val_acc: 0.4196\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 47/100\n",
            "7268/7268 [==============================] - 1s 195us/step - loss: 3.0380e-07 - acc: 0.2565 - val_loss: 4.0446e-07 - val_acc: 0.6918\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00000\n",
            "Epoch 48/100\n",
            "7268/7268 [==============================] - 1s 194us/step - loss: 8.2828e-07 - acc: 0.2632 - val_loss: 5.5121e-06 - val_acc: 0.0767\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00000\n",
            "Epoch 49/100\n",
            "7268/7268 [==============================] - 1s 200us/step - loss: 1.8045e-04 - acc: 0.1639 - val_loss: 9.7905e-04 - val_acc: 0.1002\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00000\n",
            "Epoch 50/100\n",
            "7268/7268 [==============================] - 1s 197us/step - loss: 3.0715e-04 - acc: 0.1882 - val_loss: 6.2407e-06 - val_acc: 0.2933\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00000\n",
            "Epoch 51/100\n",
            "7268/7268 [==============================] - 1s 200us/step - loss: 1.4406e-06 - acc: 0.3448 - val_loss: 9.4657e-08 - val_acc: 0.0879\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 52/100\n",
            "7268/7268 [==============================] - 1s 196us/step - loss: 4.5039e-08 - acc: 0.2975 - val_loss: 1.8372e-08 - val_acc: 0.3923\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00000\n",
            "Epoch 53/100\n",
            "7268/7268 [==============================] - 1s 196us/step - loss: 8.1767e-08 - acc: 0.3206 - val_loss: 3.6190e-07 - val_acc: 0.0693\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.00000\n",
            "Epoch 54/100\n",
            "7268/7268 [==============================] - 1s 206us/step - loss: 3.7617e-06 - acc: 0.2770 - val_loss: 1.7038e-05 - val_acc: 0.2141\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.00000\n",
            "Epoch 55/100\n",
            "7268/7268 [==============================] - 1s 192us/step - loss: 2.0546e-04 - acc: 0.1761 - val_loss: 2.1701e-04 - val_acc: 0.1597\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.00000\n",
            "Epoch 56/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 9.3729e-05 - acc: 0.1943 - val_loss: 1.7077e-05 - val_acc: 0.2178\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 57/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 6.7934e-06 - acc: 0.1859 - val_loss: 3.7253e-06 - val_acc: 0.1262\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.00000\n",
            "Epoch 58/100\n",
            "7268/7268 [==============================] - 1s 200us/step - loss: 6.9524e-06 - acc: 0.1716 - val_loss: 3.9803e-05 - val_acc: 0.0198\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00000\n",
            "Epoch 59/100\n",
            "7268/7268 [==============================] - 1s 197us/step - loss: 3.9229e-04 - acc: 0.1815 - val_loss: 4.4148e-04 - val_acc: 0.1002\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00000\n",
            "Epoch 60/100\n",
            "7268/7268 [==============================] - 1s 201us/step - loss: 5.6983e-05 - acc: 0.1644 - val_loss: 1.6506e-06 - val_acc: 0.6015\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.00000\n",
            "Epoch 61/100\n",
            "7268/7268 [==============================] - 1s 200us/step - loss: 1.5668e-06 - acc: 0.4139 - val_loss: 2.4302e-08 - val_acc: 0.4196\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 62/100\n",
            "7268/7268 [==============================] - 1s 196us/step - loss: 9.6328e-09 - acc: 0.1935 - val_loss: 3.6256e-09 - val_acc: 0.6708\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.00000\n",
            "Epoch 63/100\n",
            "7268/7268 [==============================] - 1s 193us/step - loss: 2.8976e-09 - acc: 0.1750 - val_loss: 5.8320e-09 - val_acc: 0.1163\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00000\n",
            "Epoch 64/100\n",
            "7268/7268 [==============================] - 1s 196us/step - loss: 6.2578e-08 - acc: 0.1797 - val_loss: 2.9438e-07 - val_acc: 0.2723\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00000\n",
            "Epoch 65/100\n",
            "7268/7268 [==============================] - 1s 194us/step - loss: 2.7483e-05 - acc: 0.1774 - val_loss: 2.9039e-04 - val_acc: 0.2624\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00000\n",
            "Epoch 66/100\n",
            "7268/7268 [==============================] - 1s 200us/step - loss: 3.4229e-04 - acc: 0.1709 - val_loss: 2.9890e-05 - val_acc: 0.1609\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 67/100\n",
            "7268/7268 [==============================] - 1s 203us/step - loss: 9.8775e-06 - acc: 0.1599 - val_loss: 3.8748e-06 - val_acc: 0.0767\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00000\n",
            "Epoch 68/100\n",
            "7268/7268 [==============================] - 1s 196us/step - loss: 1.4226e-06 - acc: 0.3038 - val_loss: 1.1230e-06 - val_acc: 0.0879\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00000\n",
            "Epoch 69/100\n",
            "7268/7268 [==============================] - 1s 198us/step - loss: 2.7639e-06 - acc: 0.2821 - val_loss: 1.0652e-05 - val_acc: 0.0842\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.00000\n",
            "Epoch 70/100\n",
            "7268/7268 [==============================] - 1s 197us/step - loss: 7.4530e-05 - acc: 0.1868 - val_loss: 3.2428e-04 - val_acc: 0.3416\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.00000\n",
            "Epoch 71/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 1.7171e-04 - acc: 0.1849 - val_loss: 4.3757e-05 - val_acc: 0.1436\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 72/100\n",
            "7268/7268 [==============================] - 1s 194us/step - loss: 1.3898e-05 - acc: 0.1857 - val_loss: 2.2558e-06 - val_acc: 0.1188\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.00000\n",
            "Epoch 73/100\n",
            "7268/7268 [==============================] - 1s 195us/step - loss: 3.8019e-06 - acc: 0.3229 - val_loss: 5.8185e-06 - val_acc: 0.3379\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00000\n",
            "Epoch 74/100\n",
            "7268/7268 [==============================] - 2s 210us/step - loss: 1.4389e-04 - acc: 0.1699 - val_loss: 6.1028e-04 - val_acc: 0.1188\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.00000\n",
            "Epoch 75/100\n",
            "7268/7268 [==============================] - 1s 205us/step - loss: 1.6714e-04 - acc: 0.1618 - val_loss: 8.4127e-06 - val_acc: 0.2785\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00000\n",
            "Epoch 76/100\n",
            "7268/7268 [==============================] - 2s 212us/step - loss: 2.7493e-06 - acc: 0.1845 - val_loss: 5.0531e-07 - val_acc: 0.3379\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 77/100\n",
            "7268/7268 [==============================] - 2s 212us/step - loss: 2.6076e-07 - acc: 0.1747 - val_loss: 7.8023e-08 - val_acc: 0.0990\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00000\n",
            "Epoch 78/100\n",
            "7268/7268 [==============================] - 2s 210us/step - loss: 1.6542e-07 - acc: 0.1721 - val_loss: 6.2173e-07 - val_acc: 0.0780\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.00000\n",
            "Epoch 79/100\n",
            "7268/7268 [==============================] - 2s 210us/step - loss: 1.6326e-05 - acc: 0.1893 - val_loss: 1.3349e-04 - val_acc: 0.4876\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00000\n",
            "Epoch 80/100\n",
            "7268/7268 [==============================] - 2s 210us/step - loss: 2.9981e-04 - acc: 0.1930 - val_loss: 1.0184e-04 - val_acc: 0.1770\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00000\n",
            "Epoch 81/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 4.1741e-05 - acc: 0.1950 - val_loss: 4.1644e-06 - val_acc: 0.1757\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 82/100\n",
            "7268/7268 [==============================] - 1s 203us/step - loss: 1.1434e-06 - acc: 0.2423 - val_loss: 1.8215e-07 - val_acc: 0.2983\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00000\n",
            "Epoch 83/100\n",
            "7268/7268 [==============================] - 1s 198us/step - loss: 1.3943e-07 - acc: 0.2822 - val_loss: 1.5017e-07 - val_acc: 0.5854\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00000\n",
            "Epoch 84/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 1.0534e-06 - acc: 0.4018 - val_loss: 2.6274e-06 - val_acc: 0.4728\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00000\n",
            "Epoch 85/100\n",
            "7268/7268 [==============================] - 1s 197us/step - loss: 1.0841e-04 - acc: 0.1944 - val_loss: 4.3447e-04 - val_acc: 0.2921\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.00000\n",
            "Epoch 86/100\n",
            "7268/7268 [==============================] - 1s 193us/step - loss: 2.3096e-04 - acc: 0.1789 - val_loss: 8.4415e-06 - val_acc: 0.0990\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 87/100\n",
            "7268/7268 [==============================] - 1s 193us/step - loss: 2.8533e-06 - acc: 0.1895 - val_loss: 1.0451e-07 - val_acc: 0.4146\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00000\n",
            "Epoch 88/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 8.4580e-08 - acc: 0.2536 - val_loss: 6.1739e-08 - val_acc: 0.0755\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00000\n",
            "Epoch 89/100\n",
            "7268/7268 [==============================] - 1s 202us/step - loss: 9.7573e-08 - acc: 0.3671 - val_loss: 1.6531e-06 - val_acc: 0.1324\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00000\n",
            "Epoch 90/100\n",
            "7268/7268 [==============================] - 1s 197us/step - loss: 1.3722e-06 - acc: 0.3430 - val_loss: 6.1512e-06 - val_acc: 0.3106\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00000\n",
            "Epoch 91/100\n",
            "7268/7268 [==============================] - 1s 198us/step - loss: 1.1694e-04 - acc: 0.1911 - val_loss: 5.4878e-04 - val_acc: 0.0705\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 92/100\n",
            "7268/7268 [==============================] - 1s 198us/step - loss: 2.4047e-04 - acc: 0.1626 - val_loss: 1.7534e-05 - val_acc: 0.1089\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00000\n",
            "Epoch 93/100\n",
            "7268/7268 [==============================] - 1s 197us/step - loss: 5.0523e-06 - acc: 0.1862 - val_loss: 6.5470e-08 - val_acc: 0.1361\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.00000\n",
            "Epoch 94/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 1.2357e-08 - acc: 0.1570 - val_loss: 2.8439e-09 - val_acc: 0.2166\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.00000\n",
            "Epoch 95/100\n",
            "7268/7268 [==============================] - 1s 197us/step - loss: 1.6572e-09 - acc: 0.1714 - val_loss: 1.3208e-09 - val_acc: 0.3428\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00000\n",
            "Epoch 96/100\n",
            "7268/7268 [==============================] - 1s 197us/step - loss: 5.6715e-09 - acc: 0.1882 - val_loss: 2.6342e-08 - val_acc: 0.4010\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.003.\n",
            "Epoch 97/100\n",
            "7268/7268 [==============================] - 1s 199us/step - loss: 2.2284e-06 - acc: 0.2910 - val_loss: 1.5425e-05 - val_acc: 0.0124\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00000\n",
            "Epoch 98/100\n",
            "7268/7268 [==============================] - 1s 198us/step - loss: 2.8854e-04 - acc: 0.1845 - val_loss: 2.3144e-04 - val_acc: 0.0854\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00000\n",
            "Epoch 99/100\n",
            "7268/7268 [==============================] - 1s 196us/step - loss: 6.0827e-05 - acc: 0.1727 - val_loss: 4.0992e-07 - val_acc: 0.1559\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.00000\n",
            "Epoch 100/100\n",
            "7268/7268 [==============================] - 1s 198us/step - loss: 1.4014e-07 - acc: 0.1648 - val_loss: 1.0934e-08 - val_acc: 0.0582\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NG2n5wzubtRR",
        "colab": {}
      },
      "source": [
        "output = model.predict(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cxfhJDgEjk1k",
        "outputId": "b2bbcb50-a1b8-402f-9faf-135f9de36301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(output[0])"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.0000004e+00  9.9996912e-01  1.0000355e+00  1.0000186e+00\n",
            " -1.1737347e-04 -3.7604572e-05 -1.1823178e-04 -6.3049796e-05]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i2EM52czjp3d",
        "outputId": "8cb2dc47-98d0-4a00-abe7-91c39b81b7c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(Y_train[0])"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6udUI3uBQqY8",
        "outputId": "ec038ea8-ad01-48be-9aeb-5d6ac52ef584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(output.shape)"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8076, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "42-FGlV9ezAb",
        "colab": {}
      },
      "source": [
        "def change_output(arr):\n",
        "    '''' Rounding off the confident outputs '''\n",
        "    row=arr.shape[0]\n",
        "    col=arr.shape[1]\n",
        "    for i in range(row):\n",
        "      for j in range(col):\n",
        "        if(arr[i][j]>0.5):\n",
        "          arr[i][j]=1\n",
        "        else:\n",
        "          arr[i][j]=0\n",
        "          \n",
        "    arr.astype('int')\n",
        "    return(arr)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KThKObMJQ9ZL",
        "colab": {}
      },
      "source": [
        "def accuracy(Y_pred, Y_train):\n",
        "    ''' Given the predicted array, it compares it with the hashmap and gives the accuracy score '''\n",
        "    Y_pred_int = change_output(Y_pred)\n",
        "    print(\"Accuracy for the given batch is :\", accuracy_score(Y_pred, Y_train) * 100 , \" % \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ddy_IWe2Apai",
        "outputId": "33d1634a-fb60-45bf-c55b-60e0a6f3b400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "Y_pred = model.predict(X_train)\n",
        "accuracy(Y_pred, Y_train)"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for the given batch is : 100.0  % \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3qA1Xn9ASVSF",
        "outputId": "937089b3-da7f-40e9-e6f8-6e21cdef64fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(Y_train.shape)"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8076, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLMc22jToFSe",
        "colab_type": "code",
        "outputId": "9e1cea9f-5000-4fe0-be13-9004b1a28a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "Y_test_pred = model.predict(X_test)\n",
        "accuracy(Y_test_pred, Y_test)"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for the given batch is : 100.0  % \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AjmBxjI6R2ek",
        "colab": {}
      },
      "source": [
        "decrypter = Sequential()\n",
        "\n",
        "decrypter.add(layers.Dense(16, input_shape = (8,)))\n",
        "decrypter.add(layers.LeakyReLU())\n",
        "\n",
        "decrypter.add(layers.Dense(32))\n",
        "decrypter.add(layers.LeakyReLU())\n",
        "\n",
        "decrypter.add(layers.Dense(40))\n",
        "decrypter.add(layers.LeakyReLU())\n",
        "\n",
        "decrypter.add(layers.Dense(54))\n",
        "decrypter.add(layers.LeakyReLU())\n",
        "\n",
        "decrypter.add(layers.Dense(64))\n",
        "decrypter.add(layers.LeakyReLU())\n",
        "\n",
        "decrypter.add(layers.Dense(91))\n",
        "decrypter.add(layers.LeakyReLU())\n",
        "\n",
        "decrypter.add(layers.Dense(91))\n",
        "decrypter.add(layers.LeakyReLU())\n",
        "\n",
        "decrypter.add(layers.Dense(91))\n",
        "decrypter.add(layers.LeakyReLU())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vaLReXz2T295",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.0015\n",
        "epochs = 100\n",
        "batch_size = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vhs2BefhVXOh",
        "colab": {}
      },
      "source": [
        "decrypter_optimizer = optimizers.Adam(lr = learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-pkRbDzwVUEk",
        "colab": {}
      },
      "source": [
        "decrypter.compile(optimizer=decrypter_optimizer, loss = 'mean_squared_error', metrics = ['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5KtULAzpVMnB",
        "colab": {}
      },
      "source": [
        "decrypter_X_train = Y_train\n",
        "decrypter_Y_train = X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULve7e9hBMyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decrypter_X_test = Y_test_pred\n",
        "decrypter_Y_test = X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eUvLtRt_WE2z",
        "outputId": "fe1743d7-b83b-485d-e58e-dc152d6dec96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(decrypter_X_train.shape)\n",
        "print(decrypter_Y_train.shape)"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8076, 8)\n",
            "(8076, 91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQnr82iGBmXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "85f1eb34-d507-4a4f-fcda-b11304b92923"
      },
      "source": [
        "print(decrypter_X_test.shape)\n",
        "print(decrypter_Y_test.shape)"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49, 8)\n",
            "(49, 91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l24tT32UWJ_K",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint('/content/denrypt_1.h5', monitor = 'val_loss', verbose = 1, save_best_only = True, save_weights_only = True)\n",
        "reducelr = ReduceLROnPlateau(monitor = 'val_loss', verbose = 1, patience = 5,factor = 0.05, min_lr = 0.003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y2FyLCfgXuJM",
        "outputId": "74252709-ad77-4d9d-bd73-34b71a56a358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "decrypter_history = decrypter.fit(decrypter_X_train, decrypter_Y_train,\n",
        "                              batch_size = None,\n",
        "                              epochs = epochs, verbose = 1,\n",
        "                              callbacks = [checkpoint, reducelr],\n",
        "                              validation_split = 0.1)"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7268 samples, validate on 808 samples\n",
            "Epoch 1/100\n",
            "7268/7268 [==============================] - 3s 466us/step - loss: 0.0073 - acc: 0.6453 - val_loss: 0.0041 - val_acc: 0.9938\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00410, saving model to /content/denrypt_1.h5\n",
            "Epoch 2/100\n",
            "7268/7268 [==============================] - 2s 217us/step - loss: 0.0024 - acc: 0.9979 - val_loss: 0.0014 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.00410 to 0.00139, saving model to /content/denrypt_1.h5\n",
            "Epoch 3/100\n",
            "7268/7268 [==============================] - 2s 222us/step - loss: 9.9035e-04 - acc: 1.0000 - val_loss: 7.7004e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00139 to 0.00077, saving model to /content/denrypt_1.h5\n",
            "Epoch 4/100\n",
            "7268/7268 [==============================] - 2s 224us/step - loss: 5.9985e-04 - acc: 1.0000 - val_loss: 5.2541e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00077 to 0.00053, saving model to /content/denrypt_1.h5\n",
            "Epoch 5/100\n",
            "7268/7268 [==============================] - 2s 215us/step - loss: 4.2781e-04 - acc: 1.0000 - val_loss: 3.7875e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00053 to 0.00038, saving model to /content/denrypt_1.h5\n",
            "Epoch 6/100\n",
            "7268/7268 [==============================] - 2s 219us/step - loss: 3.2312e-04 - acc: 1.0000 - val_loss: 2.9668e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00038 to 0.00030, saving model to /content/denrypt_1.h5\n",
            "Epoch 7/100\n",
            "7268/7268 [==============================] - 2s 223us/step - loss: 2.3717e-04 - acc: 1.0000 - val_loss: 2.1631e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00030 to 0.00022, saving model to /content/denrypt_1.h5\n",
            "Epoch 8/100\n",
            "7268/7268 [==============================] - 2s 224us/step - loss: 1.9490e-04 - acc: 1.0000 - val_loss: 2.1734e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00022\n",
            "Epoch 9/100\n",
            "7268/7268 [==============================] - 2s 216us/step - loss: 1.6551e-04 - acc: 1.0000 - val_loss: 6.6780e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.00022\n",
            "Epoch 10/100\n",
            "7268/7268 [==============================] - 2s 223us/step - loss: 1.5904e-04 - acc: 1.0000 - val_loss: 8.5894e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00022 to 0.00009, saving model to /content/denrypt_1.h5\n",
            "Epoch 11/100\n",
            "7268/7268 [==============================] - 2s 217us/step - loss: 7.5526e-05 - acc: 1.0000 - val_loss: 6.5486e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00009 to 0.00007, saving model to /content/denrypt_1.h5\n",
            "Epoch 12/100\n",
            "7268/7268 [==============================] - 2s 215us/step - loss: 6.1624e-05 - acc: 1.0000 - val_loss: 6.1678e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00007 to 0.00006, saving model to /content/denrypt_1.h5\n",
            "Epoch 13/100\n",
            "7268/7268 [==============================] - 2s 213us/step - loss: 5.4701e-05 - acc: 1.0000 - val_loss: 4.9028e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00006 to 0.00005, saving model to /content/denrypt_1.h5\n",
            "Epoch 14/100\n",
            "7268/7268 [==============================] - 2s 218us/step - loss: 4.2538e-05 - acc: 1.0000 - val_loss: 6.8968e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00005\n",
            "Epoch 15/100\n",
            "7268/7268 [==============================] - 2s 214us/step - loss: 5.6433e-05 - acc: 1.0000 - val_loss: 2.7223e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00005 to 0.00003, saving model to /content/denrypt_1.h5\n",
            "Epoch 16/100\n",
            "7268/7268 [==============================] - 2s 218us/step - loss: 2.9189e-05 - acc: 1.0000 - val_loss: 4.1084e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00003\n",
            "Epoch 17/100\n",
            "7268/7268 [==============================] - 2s 220us/step - loss: 2.7292e-05 - acc: 1.0000 - val_loss: 1.5312e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00003 to 0.00002, saving model to /content/denrypt_1.h5\n",
            "Epoch 18/100\n",
            "7268/7268 [==============================] - 2s 219us/step - loss: 1.6447e-05 - acc: 1.0000 - val_loss: 6.8162e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00002\n",
            "Epoch 19/100\n",
            "7268/7268 [==============================] - 2s 221us/step - loss: 5.9628e-05 - acc: 1.0000 - val_loss: 4.2922e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00002\n",
            "Epoch 20/100\n",
            "7268/7268 [==============================] - 2s 220us/step - loss: 1.7133e-05 - acc: 1.0000 - val_loss: 8.6796e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00002 to 0.00001, saving model to /content/denrypt_1.h5\n",
            "Epoch 21/100\n",
            "7268/7268 [==============================] - 2s 218us/step - loss: 7.4148e-06 - acc: 1.0000 - val_loss: 1.4400e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00001\n",
            "Epoch 22/100\n",
            "7268/7268 [==============================] - 2s 213us/step - loss: 1.0879e-04 - acc: 1.0000 - val_loss: 4.0109e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00001\n",
            "Epoch 23/100\n",
            "7268/7268 [==============================] - 2s 219us/step - loss: 7.4835e-05 - acc: 1.0000 - val_loss: 2.3999e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00001 to 0.00000, saving model to /content/denrypt_1.h5\n",
            "Epoch 24/100\n",
            "7268/7268 [==============================] - 2s 219us/step - loss: 9.0790e-07 - acc: 1.0000 - val_loss: 3.0646e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00000 to 0.00000, saving model to /content/denrypt_1.h5\n",
            "Epoch 25/100\n",
            "7268/7268 [==============================] - 2s 216us/step - loss: 1.7619e-07 - acc: 1.0000 - val_loss: 9.0268e-08 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.00000 to 0.00000, saving model to /content/denrypt_1.h5\n",
            "Epoch 26/100\n",
            "7268/7268 [==============================] - 2s 217us/step - loss: 8.4774e-08 - acc: 1.0000 - val_loss: 1.1818e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00000\n",
            "Epoch 27/100\n",
            "7268/7268 [==============================] - 2s 219us/step - loss: 7.3166e-07 - acc: 1.0000 - val_loss: 6.4822e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00000\n",
            "Epoch 28/100\n",
            "7268/7268 [==============================] - 2s 216us/step - loss: 6.8622e-05 - acc: 1.0000 - val_loss: 1.4793e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00000\n",
            "Epoch 29/100\n",
            "7268/7268 [==============================] - 2s 220us/step - loss: 4.4474e-05 - acc: 1.0000 - val_loss: 3.3299e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00000\n",
            "Epoch 30/100\n",
            "7268/7268 [==============================] - 2s 224us/step - loss: 1.1937e-06 - acc: 1.0000 - val_loss: 4.3573e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00000\n",
            "Epoch 31/100\n",
            "7268/7268 [==============================] - 2s 216us/step - loss: 4.2902e-07 - acc: 1.0000 - val_loss: 1.3503e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00000\n",
            "Epoch 32/100\n",
            "7268/7268 [==============================] - 2s 223us/step - loss: 1.0420e-05 - acc: 1.0000 - val_loss: 6.8206e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00000\n",
            "Epoch 33/100\n",
            "7268/7268 [==============================] - 2s 218us/step - loss: 1.2150e-04 - acc: 1.0000 - val_loss: 1.8517e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00000\n",
            "Epoch 34/100\n",
            "7268/7268 [==============================] - 2s 219us/step - loss: 5.2590e-06 - acc: 1.0000 - val_loss: 4.7409e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00000\n",
            "Epoch 35/100\n",
            "7268/7268 [==============================] - 2s 220us/step - loss: 3.2212e-07 - acc: 1.0000 - val_loss: 1.5702e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00000\n",
            "Epoch 36/100\n",
            "7268/7268 [==============================] - 2s 215us/step - loss: 2.6604e-07 - acc: 1.0000 - val_loss: 1.0678e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00000\n",
            "Epoch 37/100\n",
            "7268/7268 [==============================] - 2s 223us/step - loss: 5.0610e-06 - acc: 1.0000 - val_loss: 2.7455e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00000\n",
            "Epoch 38/100\n",
            "7268/7268 [==============================] - 2s 220us/step - loss: 1.0225e-04 - acc: 1.0000 - val_loss: 3.2005e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00000\n",
            "Epoch 39/100\n",
            "7268/7268 [==============================] - 2s 217us/step - loss: 9.6897e-06 - acc: 1.0000 - val_loss: 4.8174e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00000\n",
            "Epoch 40/100\n",
            "7268/7268 [==============================] - 2s 219us/step - loss: 1.5354e-07 - acc: 1.0000 - val_loss: 7.0498e-08 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.00000 to 0.00000, saving model to /content/denrypt_1.h5\n",
            "Epoch 41/100\n",
            "7268/7268 [==============================] - 2s 223us/step - loss: 8.1405e-08 - acc: 1.0000 - val_loss: 1.4702e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00000\n",
            "Epoch 42/100\n",
            "7268/7268 [==============================] - 2s 224us/step - loss: 1.3617e-06 - acc: 1.0000 - val_loss: 8.7699e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00000\n",
            "Epoch 43/100\n",
            "7268/7268 [==============================] - 2s 221us/step - loss: 8.8385e-05 - acc: 1.0000 - val_loss: 6.8807e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00000\n",
            "Epoch 44/100\n",
            "7268/7268 [==============================] - 2s 219us/step - loss: 1.2614e-05 - acc: 1.0000 - val_loss: 1.0070e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00000\n",
            "Epoch 45/100\n",
            "7268/7268 [==============================] - 2s 221us/step - loss: 5.5619e-07 - acc: 1.0000 - val_loss: 3.2857e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00000\n",
            "Epoch 46/100\n",
            "7268/7268 [==============================] - 2s 216us/step - loss: 6.1639e-07 - acc: 1.0000 - val_loss: 1.1847e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00000\n",
            "Epoch 47/100\n",
            "7268/7268 [==============================] - 2s 220us/step - loss: 1.9694e-05 - acc: 1.0000 - val_loss: 1.5235e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00000\n",
            "Epoch 48/100\n",
            "7268/7268 [==============================] - 2s 218us/step - loss: 6.0802e-05 - acc: 1.0000 - val_loss: 4.6130e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00000\n",
            "Epoch 49/100\n",
            "7268/7268 [==============================] - 2s 220us/step - loss: 1.4871e-06 - acc: 1.0000 - val_loss: 6.6142e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00000\n",
            "Epoch 50/100\n",
            "7268/7268 [==============================] - 2s 221us/step - loss: 3.8930e-07 - acc: 1.0000 - val_loss: 4.3492e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00000\n",
            "Epoch 51/100\n",
            "7268/7268 [==============================] - 2s 220us/step - loss: 7.0360e-06 - acc: 1.0000 - val_loss: 8.1536e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00000\n",
            "Epoch 52/100\n",
            "7268/7268 [==============================] - 2s 216us/step - loss: 1.1598e-04 - acc: 1.0000 - val_loss: 3.3048e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00000\n",
            "Epoch 53/100\n",
            "7268/7268 [==============================] - 2s 218us/step - loss: 7.2639e-07 - acc: 1.0000 - val_loss: 1.1754e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.00000\n",
            "Epoch 54/100\n",
            "7268/7268 [==============================] - 2s 219us/step - loss: 5.3329e-08 - acc: 1.0000 - val_loss: 2.4131e-08 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.00000 to 0.00000, saving model to /content/denrypt_1.h5\n",
            "Epoch 55/100\n",
            "7268/7268 [==============================] - 2s 219us/step - loss: 1.9837e-08 - acc: 1.0000 - val_loss: 2.6024e-08 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.00000\n",
            "Epoch 56/100\n",
            "7268/7268 [==============================] - 2s 228us/step - loss: 8.1578e-08 - acc: 1.0000 - val_loss: 3.5358e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00000\n",
            "Epoch 57/100\n",
            "7268/7268 [==============================] - 2s 235us/step - loss: 1.3875e-05 - acc: 1.0000 - val_loss: 6.7274e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.00000\n",
            "Epoch 58/100\n",
            "7268/7268 [==============================] - 2s 228us/step - loss: 8.1265e-05 - acc: 1.0000 - val_loss: 9.7867e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00000\n",
            "Epoch 59/100\n",
            "7268/7268 [==============================] - 2s 226us/step - loss: 3.9239e-06 - acc: 1.0000 - val_loss: 3.7095e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00000\n",
            "Epoch 60/100\n",
            "7268/7268 [==============================] - 2s 232us/step - loss: 2.3414e-07 - acc: 1.0000 - val_loss: 7.9557e-08 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.00000\n",
            "Epoch 61/100\n",
            "7268/7268 [==============================] - 2s 230us/step - loss: 8.5213e-08 - acc: 1.0000 - val_loss: 1.8562e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.00000\n",
            "Epoch 62/100\n",
            "7268/7268 [==============================] - 2s 225us/step - loss: 7.8510e-06 - acc: 1.0000 - val_loss: 6.2803e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.00000\n",
            "Epoch 63/100\n",
            "7268/7268 [==============================] - 2s 222us/step - loss: 5.5223e-05 - acc: 1.0000 - val_loss: 1.1359e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00000\n",
            "Epoch 64/100\n",
            "7268/7268 [==============================] - 2s 218us/step - loss: 4.3249e-06 - acc: 1.0000 - val_loss: 7.2177e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00000\n",
            "Epoch 65/100\n",
            "7268/7268 [==============================] - 2s 225us/step - loss: 6.9665e-06 - acc: 1.0000 - val_loss: 1.2643e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00000\n",
            "Epoch 66/100\n",
            "7268/7268 [==============================] - 2s 221us/step - loss: 2.1786e-05 - acc: 1.0000 - val_loss: 9.6316e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00000\n",
            "Epoch 67/100\n",
            "7268/7268 [==============================] - 2s 217us/step - loss: 4.6895e-05 - acc: 1.0000 - val_loss: 4.5824e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00000\n",
            "Epoch 68/100\n",
            "7268/7268 [==============================] - 2s 219us/step - loss: 1.3548e-06 - acc: 1.0000 - val_loss: 2.5134e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00000\n",
            "Epoch 69/100\n",
            "7268/7268 [==============================] - 2s 215us/step - loss: 1.4020e-07 - acc: 1.0000 - val_loss: 1.8652e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.00000\n",
            "Epoch 70/100\n",
            "7268/7268 [==============================] - 2s 218us/step - loss: 8.3677e-07 - acc: 1.0000 - val_loss: 3.3033e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.00000\n",
            "Epoch 71/100\n",
            "7268/7268 [==============================] - 2s 217us/step - loss: 8.4669e-05 - acc: 1.0000 - val_loss: 8.2376e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00000\n",
            "Epoch 72/100\n",
            "7268/7268 [==============================] - 2s 214us/step - loss: 1.9066e-05 - acc: 1.0000 - val_loss: 4.6594e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.00000\n",
            "Epoch 73/100\n",
            "7268/7268 [==============================] - 2s 220us/step - loss: 1.3973e-07 - acc: 1.0000 - val_loss: 3.1146e-08 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00000\n",
            "Epoch 74/100\n",
            "7268/7268 [==============================] - 2s 219us/step - loss: 2.7686e-08 - acc: 1.0000 - val_loss: 1.6829e-08 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.00000 to 0.00000, saving model to /content/denrypt_1.h5\n",
            "Epoch 75/100\n",
            "7268/7268 [==============================] - 2s 223us/step - loss: 3.9294e-08 - acc: 1.0000 - val_loss: 9.8249e-08 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00000\n",
            "Epoch 76/100\n",
            "7268/7268 [==============================] - 2s 221us/step - loss: 4.4218e-07 - acc: 1.0000 - val_loss: 7.0307e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.00000\n",
            "Epoch 77/100\n",
            "7268/7268 [==============================] - 2s 217us/step - loss: 6.2010e-05 - acc: 1.0000 - val_loss: 6.0599e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00000\n",
            "Epoch 78/100\n",
            "7268/7268 [==============================] - 2s 217us/step - loss: 2.0488e-05 - acc: 1.0000 - val_loss: 1.6424e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.00000\n",
            "Epoch 79/100\n",
            "7268/7268 [==============================] - 2s 222us/step - loss: 1.2635e-06 - acc: 1.0000 - val_loss: 3.1874e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00000\n",
            "Epoch 80/100\n",
            "7268/7268 [==============================] - 2s 219us/step - loss: 1.9938e-07 - acc: 1.0000 - val_loss: 2.2153e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00000\n",
            "Epoch 81/100\n",
            "7268/7268 [==============================] - 2s 228us/step - loss: 1.1695e-05 - acc: 1.0000 - val_loss: 9.7530e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.00000\n",
            "Epoch 82/100\n",
            "7268/7268 [==============================] - 2s 228us/step - loss: 6.4553e-05 - acc: 1.0000 - val_loss: 2.7194e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00000\n",
            "Epoch 83/100\n",
            "7268/7268 [==============================] - 2s 229us/step - loss: 6.9424e-07 - acc: 1.0000 - val_loss: 1.5454e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00000\n",
            "Epoch 84/100\n",
            "7268/7268 [==============================] - 2s 220us/step - loss: 8.2533e-08 - acc: 1.0000 - val_loss: 2.7229e-08 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00000\n",
            "Epoch 85/100\n",
            "7268/7268 [==============================] - 2s 217us/step - loss: 6.0589e-08 - acc: 1.0000 - val_loss: 2.1800e-07 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.00000\n",
            "Epoch 86/100\n",
            "7268/7268 [==============================] - 2s 219us/step - loss: 2.0111e-06 - acc: 1.0000 - val_loss: 2.3201e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00000\n",
            "Epoch 87/100\n",
            "7268/7268 [==============================] - 2s 218us/step - loss: 5.4419e-05 - acc: 1.0000 - val_loss: 2.1406e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00000\n",
            "Epoch 88/100\n",
            "7268/7268 [==============================] - 2s 218us/step - loss: 7.8250e-06 - acc: 1.0000 - val_loss: 4.2887e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00000\n",
            "Epoch 89/100\n",
            "7268/7268 [==============================] - 2s 220us/step - loss: 9.9370e-06 - acc: 1.0000 - val_loss: 7.3946e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00000\n",
            "Epoch 90/100\n",
            "7268/7268 [==============================] - 2s 221us/step - loss: 3.8266e-06 - acc: 1.0000 - val_loss: 4.2323e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00000\n",
            "Epoch 91/100\n",
            "7268/7268 [==============================] - 2s 221us/step - loss: 2.2840e-05 - acc: 1.0000 - val_loss: 5.2410e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00000\n",
            "Epoch 92/100\n",
            "7268/7268 [==============================] - 2s 217us/step - loss: 3.3132e-05 - acc: 1.0000 - val_loss: 7.3270e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00000\n",
            "Epoch 93/100\n",
            "7268/7268 [==============================] - 2s 219us/step - loss: 3.1732e-06 - acc: 1.0000 - val_loss: 1.2013e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.00000\n",
            "Epoch 94/100\n",
            "7268/7268 [==============================] - 2s 214us/step - loss: 1.1850e-06 - acc: 1.0000 - val_loss: 2.4994e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.00000\n",
            "Epoch 95/100\n",
            "7268/7268 [==============================] - 2s 216us/step - loss: 1.0349e-05 - acc: 1.0000 - val_loss: 4.0390e-05 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00000\n",
            "Epoch 96/100\n",
            "7268/7268 [==============================] - 2s 216us/step - loss: 6.6399e-05 - acc: 1.0000 - val_loss: 4.0879e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.00000\n",
            "Epoch 97/100\n",
            "7268/7268 [==============================] - 2s 220us/step - loss: 1.1490e-06 - acc: 1.0000 - val_loss: 5.2878e-08 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00000\n",
            "Epoch 98/100\n",
            "7268/7268 [==============================] - 2s 216us/step - loss: 2.3617e-08 - acc: 1.0000 - val_loss: 9.2289e-09 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.00000 to 0.00000, saving model to /content/denrypt_1.h5\n",
            "Epoch 99/100\n",
            "7268/7268 [==============================] - 2s 218us/step - loss: 4.3722e-09 - acc: 1.0000 - val_loss: 6.7312e-09 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00099: val_loss improved from 0.00000 to 0.00000, saving model to /content/denrypt_1.h5\n",
            "Epoch 100/100\n",
            "7268/7268 [==============================] - 2s 216us/step - loss: 2.2646e-07 - acc: 1.0000 - val_loss: 2.0209e-06 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IF6YSSSHYmtx",
        "colab": {}
      },
      "source": [
        "decrypted_text = decrypter.predict(decrypter_X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7yVF08xCbtFJ",
        "colab": {}
      },
      "source": [
        "decrypted_int_text = change_output(decrypted_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XZQgOIfDY6pp",
        "outputId": "a7ebb020-da4d-4242-94d3-6e647f60e848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "print(decrypted_text[0])"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "12YIpy4zhQds",
        "outputId": "65fca6ab-b59a-452a-b23b-a0163e0ec9c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "print(decrypted_int_text[0])"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3TagmGzNgf-A",
        "outputId": "394d12c9-78c9-4b83-abd1-99b8dd983dd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "print(decrypter_Y_train[0])"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PBGt8kz9cm-3",
        "outputId": "13d37b33-80fc-4b4d-eff9-5993f14f2793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(np.argmax(decrypted_text[0]))"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mOv3Lse_cqTF",
        "outputId": "775c9b12-febf-492e-e308-472831e2405f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(np.argmax(decrypter_Y_train[0]))"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uUeBDUDqgxWK",
        "outputId": "b10f47ea-196e-41f4-8ec6-ceb381ff0557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "print(decrypted_text[1])"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hUtnWwnohYRd",
        "outputId": "115054d0-2cbd-44e4-b06e-e84ce36195cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "print(decrypted_int_text[1])"
      ],
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XFO2H-Efgtd0",
        "outputId": "6bbddfdb-169e-4011-f805-62cc981aaf24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "print(decrypter_Y_train[1])"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DustfvvNZifM",
        "outputId": "f2d9c42c-9287-439c-94c2-79d106e89dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(np.argmax(decrypted_text[1]))"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4XlIEAunaqp0",
        "outputId": "b3652bf4-7265-4f5b-b642-849425494b58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(np.argmax(decrypter_Y_train[1]))"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0hmG6OSvhMQ9",
        "outputId": "a70743c2-b20d-4044-de71-60df91961023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "accuracy(decrypted_int_text, decrypter_Y_train)"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for the given batch is : 100.0  % \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fr20f-ilhj2x",
        "colab": {}
      },
      "source": [
        "decrypted_Y_test_pred = decrypter.predict(decrypter_X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jV1SYTaBH4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decrypted_Y_test_pred = change_output(decrypted_Y_test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo-1V_q7CA_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e24178e4-5c66-4ec4-b82c-3103ba77e8c5"
      },
      "source": [
        "accuracy(decrypted_Y_test_pred, decrypter_Y_test)"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for the given batch is : 100.0  % \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04rMUPA_CNiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}